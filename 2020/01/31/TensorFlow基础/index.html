<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>TensorFlow基础 - 蓝冰的博客</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="蓝冰的博客"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="蓝冰的博客"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="TensorFlow基础代码。"><meta property="og:type" content="blog"><meta property="og:title" content="TensorFlow基础"><meta property="og:url" content="http://example.com/2020/01/31/TensorFlow%E5%9F%BA%E7%A1%80/"><meta property="og:site_name" content="蓝冰的博客"><meta property="og:description" content="TensorFlow基础代码。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://example.com/img/og_image.png"><meta property="article:published_time" content="2020-01-31T04:34:46.000Z"><meta property="article:modified_time" content="2020-10-07T16:24:34.906Z"><meta property="article:author" content="Blueice"><meta property="article:tag" content="机器学习"><meta property="article:tag" content="Python"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com/2020/01/31/TensorFlow%E5%9F%BA%E7%A1%80/"},"headline":"蓝冰的博客","image":["http://example.com/img/og_image.png"],"datePublished":"2020-01-31T04:34:46.000Z","dateModified":"2020-10-07T16:24:34.906Z","author":{"@type":"Person","name":"Blueice"},"description":"TensorFlow基础代码。"}</script><link rel="canonical" href="http://example.com/2020/01/31/TensorFlow%E5%9F%BA%E7%A1%80/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.12.0/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/images/carbon.png" alt="蓝冰的博客" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/tags">Tags</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-01-31T04:34:46.000Z" title="2020-01-31T04:34:46.000Z">2020-01-31</time>发表</span><span class="level-item"><time dateTime="2020-10-07T16:24:34.906Z" title="2020-10-07T16:24:34.906Z">2020-10-08</time>更新</span><span class="level-item">14 分钟读完 (大约2160个字)</span></div></div><h1 class="title is-3 is-size-4-mobile">TensorFlow基础</h1><div class="content"><p>TensorFlow基础代码。</p>
<a id="more"></a>

<h3 id="使用graph表示计算任务"><a href="#使用graph表示计算任务" class="headerlink" title="使用graph表示计算任务"></a>使用graph表示计算任务</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">m1 = tf.constant([[<span class="number">3</span>, <span class="number">3</span>]])<span class="comment"># Create an op</span></span><br><span class="line">m2 = tf.constant([[<span class="number">2</span>], [<span class="number">3</span>]])<span class="comment"># Create an op</span></span><br><span class="line"></span><br><span class="line">product = tf.matmul(m1, m2)<span class="comment"># Create an op, Get a tensor</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    result = sess.run(product)</span><br><span class="line">    print(result)</span><br></pre></td></tr></table></figure>

<h3 id="变量的使用"><a href="#变量的使用" class="headerlink" title="变量的使用"></a>变量的使用</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">x = tf.Variable([<span class="number">1</span>, <span class="number">2</span>])</span><br><span class="line">a = tf.constant([<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"></span><br><span class="line">sub = tf.subtract(x,a)</span><br><span class="line">add = tf.add(x,sub)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    print(sess.run(sub))</span><br><span class="line">    print(sess.run(add))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># ---------Another example</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a variable and initializer it to be 0</span></span><br><span class="line">state = tf.Variable(<span class="number">0</span>,name=<span class="string">&#x27;counter&#x27;</span>)</span><br><span class="line">new_value = tf.add(state,<span class="number">1</span>)</span><br><span class="line"><span class="comment"># Give the value of &#x27;new_value&#x27; to &#x27;state&#x27;</span></span><br><span class="line">update = tf.assign(state, new_value)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    print(sess.run(state))</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        sess.run(update)</span><br><span class="line">    print(sess.run(state))</span><br></pre></td></tr></table></figure>

<h3 id="Fetch-and-Feed"><a href="#Fetch-and-Feed" class="headerlink" title="Fetch and Feed"></a>Fetch and Feed</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="comment"># ----------Fetch</span></span><br><span class="line"></span><br><span class="line">input1 = tf.constant(<span class="number">3.0</span>)</span><br><span class="line">input2 = tf.constant(<span class="number">2.0</span>)</span><br><span class="line">input3 = tf.constant(<span class="number">5.0</span>)</span><br><span class="line"></span><br><span class="line">add = tf.add(input2, input3)</span><br><span class="line">mul = tf.multiply(input1, add)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="comment"># Fetch: run many ops at the same time</span></span><br><span class="line">    result = sess.run([mul, add])</span><br><span class="line">    print(result)</span><br><span class="line"></span><br><span class="line"><span class="comment">#-------------Feed</span></span><br><span class="line"></span><br><span class="line">input1 = tf.placeholder(tf.float32)</span><br><span class="line">input2 = tf.placeholder(tf.float32)</span><br><span class="line">output = tf.multiply(input1, input2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    print(sess.run(output,feed_dict=&#123;input1:[i <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1</span>,<span class="number">5</span>)],input2:[j <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">2</span>,<span class="number">6</span>)]&#125;))</span><br></pre></td></tr></table></figure>

<h3 id="一个简单的使用案例"><a href="#一个简单的使用案例" class="headerlink" title="一个简单的使用案例"></a>一个简单的使用案例</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># Use numpy to product 100 random numbers</span></span><br><span class="line">x_data = np.random.rand(<span class="number">100</span>)</span><br><span class="line">y_data = x_data*<span class="number">0.1</span> + <span class="number">0.2</span></span><br><span class="line"></span><br><span class="line">b = tf.Variable(<span class="number">0.</span>)</span><br><span class="line">k = tf.Variable(<span class="number">0.</span>)</span><br><span class="line">y = k*x_data + b</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y_data-y))</span><br><span class="line"><span class="comment"># Define an optimizer</span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>)</span><br><span class="line">train = optimizer.minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> step <span class="keyword">in</span> range(<span class="number">20</span>):</span><br><span class="line">        sess.run(train)</span><br><span class="line">        <span class="keyword">if</span> step%<span class="number">2</span> == <span class="number">0</span>:</span><br><span class="line">            print(step, sess.run([k, b]))</span><br></pre></td></tr></table></figure>

<h3 id="手写数字数据集和softmax"><a href="#手写数字数据集和softmax" class="headerlink" title="手写数字数据集和softmax"></a>手写数字数据集和softmax</h3><ul>
<li><p>MNIST数据集</p>
<ul>
<li>60000行的训练数据集和10000行的测试数据集</li>
<li>每张图片28*28=784个像素</li>
<li>训练集张量形状为[60000, 784]，即[索引图片，索引像素点]</li>
<li>one-hot vectors，mnist.train.labels形状为[60000, 10]</li>
</ul>
</li>
<li><p>Softmax函数</p>
</li>
</ul>
<p>$$<br>\operatorname{softmax}(x)<em>{i}=\frac{\exp \left(x</em>{i}\right)}{\sum_{j} \exp \left(x_{j}\right)}<br>$$</p>
<ul>
<li>一个非线性回归的例子</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line">x_data = np.linspace(<span class="number">-0.5</span>, <span class="number">0.5</span>, <span class="number">200</span>)[:, np.newaxis]</span><br><span class="line">noise = np.random.normal(<span class="number">0</span>, <span class="number">0.02</span>, x_data.shape)</span><br><span class="line">y_data = np.square(x_data) + noise</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line">Weight_L1 = tf.Variable(tf.random_normal([<span class="number">1</span>, <span class="number">10</span>]))</span><br><span class="line">biases_L1 = tf.Variable(tf.zeros([<span class="number">1</span>, <span class="number">10</span>]))</span><br><span class="line">Wx_plus_b_L1 = tf.matmul(x, Weight_L1) + biases_L1</span><br><span class="line">L1 = tf.nn.tanh(Wx_plus_b_L1)</span><br><span class="line"></span><br><span class="line">Weights_L2 = tf.Variable(tf.random_normal([<span class="number">10</span>, <span class="number">1</span>]))</span><br><span class="line">biases_L2 = tf.Variable(tf.zeros([<span class="number">1</span>, <span class="number">1</span>]))</span><br><span class="line">Wx_plus_b_L2 = tf.matmul(L1, Weights_L2) + biases_L2</span><br><span class="line">prediction = tf.nn.tanh(Wx_plus_b_L2)</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y - prediction))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.1</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> _ <span class="keyword">in</span> range(<span class="number">2000</span>):</span><br><span class="line">        sess.run(train_step, feed_dict=&#123;x: x_data, y: y_data&#125;)</span><br><span class="line"></span><br><span class="line">    prediction_value = sess.run(prediction, feed_dict=&#123;x: x_data&#125;)</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.scatter(x_data, y_data)</span><br><span class="line">    plt.plot(x_data, prediction_value, <span class="string">&#x27;r-&#x27;</span>, lw=<span class="number">5</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>
<p>训练时不断更新<code>Weight_L1</code>，<code>biases_L1</code>，<code>Weights_L2</code>，<code>biases_L2</code>。</p>
<ul>
<li>手写数字识别（简单版本）<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data&quot;</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># Calculate the number of batch</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a simple neural network without hidden layer</span></span><br><span class="line">W = tf.Variable(tf.zeros([<span class="number">784</span>,<span class="number">10</span>]))</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]))</span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(x,W) + b)</span><br><span class="line"></span><br><span class="line">loss = tf.reduce_mean(tf.square(y-prediction))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a list of &quot;bool&quot; type</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(prediction, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step,feed_dict=&#123;x:batch_xs, y:batch_ys&#125;)</span><br><span class="line">        acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;)</span><br><span class="line">        print(<span class="string">&quot;Iter &quot;</span> + str(epoch) + <span class="string">&quot;, Testing Accuracy &quot;</span> + str(acc))</span><br></pre></td></tr></table></figure>
输出：<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">Iter 0, Testing Accuracy 0.8338</span><br><span class="line">Iter 1, Testing Accuracy 0.8715</span><br><span class="line">Iter 2, Testing Accuracy 0.8825</span><br><span class="line">Iter 3, Testing Accuracy 0.8881</span><br><span class="line">Iter 4, Testing Accuracy 0.894</span><br><span class="line">Iter 5, Testing Accuracy 0.897</span><br><span class="line">Iter 6, Testing Accuracy 0.9003</span><br><span class="line">Iter 7, Testing Accuracy 0.9012</span><br><span class="line">Iter 8, Testing Accuracy 0.9043</span><br><span class="line">Iter 9, Testing Accuracy 0.9056</span><br><span class="line">Iter 10, Testing Accuracy 0.9058</span><br><span class="line">Iter 11, Testing Accuracy 0.9075</span><br><span class="line">Iter 12, Testing Accuracy 0.9078</span><br><span class="line">Iter 13, Testing Accuracy 0.909</span><br><span class="line">Iter 14, Testing Accuracy 0.91</span><br><span class="line">Iter 15, Testing Accuracy 0.911</span><br><span class="line">Iter 16, Testing Accuracy 0.9115</span><br><span class="line">Iter 17, Testing Accuracy 0.9123</span><br><span class="line">Iter 18, Testing Accuracy 0.9133</span><br><span class="line">Iter 19, Testing Accuracy 0.9131</span><br><span class="line">Iter 20, Testing Accuracy 0.9134</span><br></pre></td></tr></table></figure>
注释：</li>
<li><code>tf.argmax()</code>函数中有个<code>axis</code>参数（轴），该参数能指定按照哪个维度计算。0：按列计算，1：行计算。</li>
<li><code>tf.cast(x, dtype, name=None)</code>。<code>x</code>：待转换的数据（张量），<code>dtype</code>：目标数据类型。</li>
<li><code>reduce_mean(input_tensor,axis=None,keep_dims=False,name=None)</code>函数用于计算张量 tensor 沿着指定的数轴（ tensor 的某一维度）上的的平均值，主要用作降维或者计算 tensor（图像）的平均值。<ul>
<li><code>tf.reduce_sum</code> ：计算 tensor 指定轴方向上的所有元素的累加和;</li>
<li><code>tf.reduce_max</code>  :  计算 tensor 指定轴方向上的各个元素的最大值;</li>
<li><code>tf.reduce_all </code>:  计算 tensor 指定轴方向上的各个元素的逻辑和（and运算）;</li>
<li><code>tf.reduce_any</code>:  计算 tensor 指定轴方向上的各个元素的逻辑或（or运算）;</li>
</ul>
</li>
</ul>
<p>改进方向（不改变方法）：</p>
<ol>
<li>改变<code>batch_size</code>大小</li>
<li>添加隐藏层，隐藏层的激活函数、神经元个数</li>
<li>权值和偏置值的初始值</li>
<li>代价函数尝试使用交叉熵</li>
<li>优化方式，学习率</li>
<li>增加<code>epoch</code>个数</li>
</ol>
<h3 id="拟合"><a href="#拟合" class="headerlink" title="拟合"></a>拟合</h3><p>防止过拟合：</p>
<ul>
<li>增加数据集</li>
<li>正则化方法</li>
<li>Dropout</li>
</ul>
<p>Dropout 的使用：只让一部分（<code>keep_prob</code>）神经元工作</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data&quot;</span>,one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line"><span class="comment"># Calculate the number of batch</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>])</span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create a simple nerual network without hidden</span></span><br><span class="line">W1 = tf.Variable(tf.truncated_normal([<span class="number">784</span>,<span class="number">2000</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b1 = tf.Variable(tf.zeros([<span class="number">2000</span>])+<span class="number">0.1</span>)</span><br><span class="line">L1 = tf.nn.tanh(tf.matmul(x,W1)+b1)</span><br><span class="line">L1_dropout = tf.nn.dropout(L1,keep_prob)</span><br><span class="line"></span><br><span class="line">W2 = tf.Variable(tf.truncated_normal([<span class="number">2000</span>,<span class="number">2000</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b2 = tf.Variable(tf.zeros([<span class="number">2000</span>])+<span class="number">0.1</span>)</span><br><span class="line">L2 = tf.nn.tanh(tf.matmul(L1_dropout,W2)+b2)</span><br><span class="line">L2_dropout = tf.nn.dropout(L2,keep_prob)</span><br><span class="line"></span><br><span class="line">W3= tf.Variable(tf.truncated_normal([<span class="number">2000</span>,<span class="number">1000</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b3 = tf.Variable(tf.zeros([<span class="number">1000</span>])+<span class="number">0.1</span>)</span><br><span class="line">L3 = tf.nn.tanh(tf.matmul(L2_dropout,W3)+b3)</span><br><span class="line">L3_dropout = tf.nn.dropout(L3,keep_prob)</span><br><span class="line"></span><br><span class="line">W4= tf.Variable(tf.truncated_normal([<span class="number">1000</span>,<span class="number">10</span>],stddev=<span class="number">0.1</span>))</span><br><span class="line">b4 = tf.Variable(tf.zeros([<span class="number">10</span>])+<span class="number">0.1</span>)</span><br><span class="line"></span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(L3_dropout,W4) + b4)</span><br><span class="line"></span><br><span class="line"><span class="comment"># loss = tf.reduce_mean(tf.square(y-prediction))</span></span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y,logits=tf.matmul(L3_dropout,W4) + b4))</span><br><span class="line">train_step = tf.train.GradientDescentOptimizer(<span class="number">0.2</span>).minimize(loss)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"><span class="comment"># Get a list of &quot;bool&quot; type</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(prediction, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"></span><br><span class="line">num_epoch = <span class="number">30</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(num_epoch):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step,feed_dict=&#123;x:batch_xs, y:batch_ys,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        test_acc = sess.run(accuracy,feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels,keep_prob:<span class="number">1.0</span>&#125;)</span><br><span class="line">        train_acc = sess.run(accuracy, feed_dict=&#123;x: mnist.train.images, y: mnist.train.labels, keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line"></span><br><span class="line">        print(<span class="string">&quot;Iter &quot;</span> + str(epoch) + <span class="string">&quot;, Testing Accuracy &quot;</span> + str(test_acc))</span><br><span class="line">        print(<span class="string">&quot;Iter &quot;</span> + str(epoch) + <span class="string">&quot;, Train Accuracy &quot;</span> + str(train_acc))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="CNN相关概念"><a href="#CNN相关概念" class="headerlink" title="CNN相关概念"></a>CNN相关概念</h3><ul>
<li><p>局部感受野：CNN通过局部感受野和权值共享减少了神经网络需要训练的参数个数</p>
</li>
<li><p>卷积操作</p>
</li>
<li><p>池化：max-pooling 和 mean-pooling</p>
</li>
<li><p>Padding</p>
<ul>
<li>SAME PADDING<ul>
<li>卷积：给平面外部补0，卷积窗口采样后得到一个跟原来平面大小相同的平面。</li>
<li>池化：可能会给外部补0。</li>
</ul>
</li>
<li>VALID PADDING<ul>
<li>卷积：不会给外部补0。卷积窗口采样后得到一个比原来平面小的平面。</li>
<li>池化：不会给外部补0。</li>
</ul>
</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&#x27;MNIST_data&#x27;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">n_batch = mnist.train.num_examples // batch_size</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">weight_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    initial = tf.truncated_normal(shape, stddev=<span class="number">0.1</span>)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">bias_variable</span>(<span class="params">shape</span>):</span></span><br><span class="line">    initial = tf.constant(<span class="number">0.1</span>, shape=shape)</span><br><span class="line">    <span class="keyword">return</span> tf.Variable(initial)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span>(<span class="params">x, W</span>):</span></span><br><span class="line">    <span class="comment"># x input: A 4-D tensor [batch, in_height, in_width, in_channels]</span></span><br><span class="line">    <span class="comment"># W filter: A 4-D tensor [filter_height, filter_width, in_channels, out_channels]</span></span><br><span class="line">    <span class="comment"># strides: A list of `ints`. strides[0] = strides[3] = 1.</span></span><br><span class="line">    <span class="comment"># strides[1] and strides[2] stand for strides for x &amp; y direction</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.conv2d(x, W, strides=[<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">max_pool_2x2</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="comment"># ksize [1, x, y, 1]</span></span><br><span class="line">    <span class="keyword">return</span> tf.nn.max_pool(x, ksize=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], strides=[<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>, <span class="number">1</span>], padding=<span class="string">&#x27;SAME&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">x = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">784</span>])</span><br><span class="line">y = tf.placeholder(tf.float32, [<span class="literal">None</span>, <span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">x_image = tf.reshape(x, [<span class="number">-1</span>, <span class="number">28</span>, <span class="number">28</span>, <span class="number">1</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># The first layer</span></span><br><span class="line">W_conv1 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">1</span>, <span class="number">32</span>])</span><br><span class="line">b_conv1 = bias_variable([<span class="number">32</span>])</span><br><span class="line"></span><br><span class="line">h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)</span><br><span class="line">h_pool1 = max_pool_2x2(h_conv1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The second layer</span></span><br><span class="line">W_conv2 = weight_variable([<span class="number">5</span>, <span class="number">5</span>, <span class="number">32</span>, <span class="number">64</span>])</span><br><span class="line">b_conv2 = bias_variable([<span class="number">64</span>])</span><br><span class="line"></span><br><span class="line">h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)</span><br><span class="line">h_pool2 = max_pool_2x2(h_conv2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The third layer</span></span><br><span class="line">W_fc1 = weight_variable([<span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>, <span class="number">1024</span>])</span><br><span class="line">b_fc1 = weight_variable([<span class="number">1024</span>])</span><br><span class="line"></span><br><span class="line">h_pool2_flat = tf.reshape(h_pool2, [<span class="number">-1</span>, <span class="number">7</span>*<span class="number">7</span>*<span class="number">64</span>])</span><br><span class="line">h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)</span><br><span class="line"></span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line">h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)</span><br><span class="line"></span><br><span class="line">W_fc2 = weight_variable([<span class="number">1024</span>, <span class="number">10</span>])</span><br><span class="line">b_fc2 = weight_variable([<span class="number">10</span>])</span><br><span class="line"></span><br><span class="line">prediction = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)</span><br><span class="line"></span><br><span class="line">cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=prediction))</span><br><span class="line"></span><br><span class="line">train_step = tf.train.AdamOptimizer(<span class="number">1e-4</span>).minimize(cross_entropy)</span><br><span class="line"></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(prediction, <span class="number">1</span>), tf.argmax(y, <span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(tf.global_variables_initializer())</span><br><span class="line">    <span class="keyword">for</span> epoch <span class="keyword">in</span> range(<span class="number">21</span>):</span><br><span class="line">        <span class="keyword">for</span> batch <span class="keyword">in</span> range(n_batch):</span><br><span class="line">            batch_xs, batch_ys = mnist.train.next_batch(batch_size)</span><br><span class="line">            sess.run(train_step, feed_dict = &#123;x: batch_xs, y: batch_ys, keep_prob: <span class="number">0.7</span>&#125;)</span><br><span class="line"></span><br><span class="line">        acc = sess.run(accuracy,feed_dict = &#123;x: mnist.test.images, y: mnist.test.labels, keep_prob: <span class="number">1.0</span>&#125;)</span><br><span class="line">        print(<span class="string">&quot;Iter &quot;</span> + str(epoch) + <span class="string">&quot;, Testing Accuracy = &quot;</span> + str(acc))</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="保存模型"><a href="#保存模型" class="headerlink" title="保存模型"></a>保存模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    <span class="comment"># train the model</span></span><br><span class="line">    saver.save(sess, <span class="string">&#x27;net/my_net.ckpt&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="读取模型"><a href="#读取模型" class="headerlink" title="读取模型"></a>读取模型</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    sess.run(init)</span><br><span class="line">    saver.restore(sess, <span class="string">&#x27;net/my_net.ckpt&#x27;</span>)</span><br></pre></td></tr></table></figure></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a><a class="link-muted mr-2" rel="tag" href="/tags/Python/">Python</a></div><!--!--></article></div><div class="card"><div class="card-content"><h3 class="menu-label has-text-centered">喜欢这篇文章？打赏一下作者吧</h3><div class="buttons is-centered"><a class="button donate" data-type="alipay"><span class="icon is-small"><i class="fab fa-alipay"></i></span><span>支付宝</span><span class="qrcode"><img src="/images/alipay.jpg" alt="支付宝"></span></a><a class="button donate" data-type="wechat"><span class="icon is-small"><i class="fab fa-weixin"></i></span><span>微信</span><span class="qrcode"><img src="/images/wechat.png" alt="微信"></span></a></div></div></div><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/2020/09/20/Collections%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/"><i class="level-item fas fa-chevron-left"></i><span class="level-item">Collections源码解析</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/2019/12/26/%E8%AE%A1%E7%AE%97%E6%97%A5%E6%9C%9F%E9%97%B4%E9%9A%94/"><span class="level-item">计算时间间隔</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><div class="card"><div class="card-content"><h3 class="title is-5">评论</h3><div class="content" id="valine-thread"></div><script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script><script src="https://cdn.jsdelivr.net/npm/valine@1.4.14/dist/Valine.min.js"></script><script>new Valine({
            el: '#valine-thread' ,
            appId: "gBb5sgRimbbsAXr7xrnRobfP-gzGzoHsz",
            appKey: "XrcjrvKU6JNxEvXYEcri34Wm",
            
            avatar: "mm",
            
            meta: ["nick","mail","link"],
            pageSize: 10,
            lang: "zh-CN",
            
            highlight: true,
            
            
            
            
            
            requiredFields: [],
        });</script></div></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/images/avatar.jpg" alt="蓝冰"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">蓝冰</p><p class="is-size-6 is-block">学生 · 软件工程</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>北京</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">6</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/blueice-thu" target="_blank" rel="noopener">关注我</a></div></div></div><!--!--><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">归档</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2021/05/"><span class="level-start"><span class="level-item">五月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">一月 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">十一月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">十月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/09/"><span class="level-start"><span class="level-item">九月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/01/"><span class="level-start"><span class="level-item">一月 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2019/12/"><span class="level-start"><span class="level-item">十二月 2019</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">标签</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Linux/"><span class="tag">Linux</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Python/"><span class="tag">Python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Win32/"><span class="tag">Win32</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"><span class="tag">机器学习</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E6%B1%87%E7%BC%96/"><span class="tag">汇编</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/%E7%AE%97%E6%B3%95/"><span class="tag">算法</span><span class="tag">1</span></a></div></div></div></div></div><div class="column-right-shadow is-hidden-widescreen is-sticky"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3 is-sticky"><div class="card widget" id="toc" data-type="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="level is-mobile" href="#使用graph表示计算任务"><span class="level-left"><span class="level-item">使用graph表示计算任务</span></span></a></li><li><a class="level is-mobile" href="#变量的使用"><span class="level-left"><span class="level-item">变量的使用</span></span></a></li><li><a class="level is-mobile" href="#Fetch-and-Feed"><span class="level-left"><span class="level-item">Fetch and Feed</span></span></a></li><li><a class="level is-mobile" href="#一个简单的使用案例"><span class="level-left"><span class="level-item">一个简单的使用案例</span></span></a></li><li><a class="level is-mobile" href="#手写数字数据集和softmax"><span class="level-left"><span class="level-item">手写数字数据集和softmax</span></span></a></li><li><a class="level is-mobile" href="#拟合"><span class="level-left"><span class="level-item">拟合</span></span></a></li><li><a class="level is-mobile" href="#CNN相关概念"><span class="level-left"><span class="level-item">CNN相关概念</span></span></a></li><li><a class="level is-mobile" href="#保存模型"><span class="level-left"><span class="level-item">保存模型</span></span></a></li><li><a class="level is-mobile" href="#读取模型"><span class="level-left"><span class="level-item">读取模型</span></span></a></li></ul></div></div><style>.menu-list > li > a.is-active + .menu-list { display: block; }.menu-list > li > a + .menu-list { display: none; }</style><script src="/js/toc.js" defer></script></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">最新文章</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-05-28T11:17:55.000Z">2021-05-28</time></p><p class="title"><a href="/2021/05/28/%E6%A6%82%E7%8E%87%E5%9F%BA%E7%A1%80/">概率基础</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-01-09T20:47:51.000Z">2021-01-10</time></p><p class="title"><a href="/2021/01/10/Linux-%E9%85%8D%E7%BD%AE%E8%B8%A9%E5%9D%91/">Linux 配置踩坑</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-11-04T03:51:47.000Z">2020-11-04</time></p><p class="title"><a href="/2020/11/04/%E5%9F%BA%E4%BA%8EWin32%E7%9A%84%E6%B8%B8%E6%88%8F%E7%A0%B4%E8%A7%A3%E4%B8%8E%E4%BF%AE%E6%94%B9/">基于Win32的游戏破解与修改</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-12T14:40:56.000Z">2020-10-12</time></p><p class="title"><a href="/2020/10/12/RadASM2%E9%85%8D%E7%BD%AE/">RadASM2配置</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-09-20T06:22:01.000Z">2020-09-20</time></p><p class="title"><a href="/2020/09/20/Collections%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90/">Collections源码解析</a></p></div></article></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/images/carbon.png" alt="蓝冰的博客" height="28"></a><p class="is-size-7"><span>&copy; 2021 Blueice</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" async></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "此网站使用Cookie来改善您的体验。",
          dismiss: "知道了！",
          allow: "允许使用Cookie",
          deny: "拒绝",
          link: "了解更多",
          policy: "Cookie政策",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>